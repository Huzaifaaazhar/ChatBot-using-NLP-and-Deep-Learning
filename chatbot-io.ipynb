{"cells":[{"cell_type":"code","execution_count":91,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-02-01T11:53:29.653348Z","iopub.status.busy":"2023-02-01T11:53:29.652913Z","iopub.status.idle":"2023-02-01T11:53:29.676804Z","shell.execute_reply":"2023-02-01T11:53:29.675911Z","shell.execute_reply.started":"2023-02-01T11:53:29.653317Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/chatbots-intent-recognition-dataset/Intent.json\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":178,"metadata":{"execution":{"iopub.execute_input":"2023-02-01T12:20:02.937672Z","iopub.status.busy":"2023-02-01T12:20:02.937267Z","iopub.status.idle":"2023-02-01T12:20:02.946074Z","shell.execute_reply":"2023-02-01T12:20:02.944786Z","shell.execute_reply.started":"2023-02-01T12:20:02.937640Z"},"trusted":true},"outputs":[],"source":["import json\n","from sklearn.feature_extraction.text import CountVectorizer\n","from scipy.spatial import distance\n","\n","#load data from json\n","with open('/kaggle/input/chatbots-intent-recognition-dataset/Intent.json') as json_file:\n","    data = json.load(json_file)\n","    \n","data = data['intents']"]},{"cell_type":"code","execution_count":179,"metadata":{"execution":{"iopub.execute_input":"2023-02-01T12:20:03.276910Z","iopub.status.busy":"2023-02-01T12:20:03.275883Z","iopub.status.idle":"2023-02-01T12:20:03.449203Z","shell.execute_reply":"2023-02-01T12:20:03.448143Z","shell.execute_reply.started":"2023-02-01T12:20:03.276872Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>intent</th>\n","      <th>text</th>\n","      <th>response</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Greeting</td>\n","      <td>Hi</td>\n","      <td>Hi human, please tell me your GeniSys user</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Greeting</td>\n","      <td>Hi there</td>\n","      <td>Hello human, please tell me your GeniSys user</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Greeting</td>\n","      <td>Hola</td>\n","      <td>Hola human, please tell me your GeniSys user</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>GreetingResponse</td>\n","      <td>My user is Adam</td>\n","      <td>Great! Hi &lt;HUMAN&gt;! How can I help?</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>GreetingResponse</td>\n","      <td>This is Adam</td>\n","      <td>Good! Hi &lt;HUMAN&gt;, how can I help you?</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             intent             text  \\\n","0          Greeting               Hi   \n","1          Greeting         Hi there   \n","2          Greeting             Hola   \n","3  GreetingResponse  My user is Adam   \n","4  GreetingResponse     This is Adam   \n","\n","                                        response  \n","0     Hi human, please tell me your GeniSys user  \n","1  Hello human, please tell me your GeniSys user  \n","2   Hola human, please tell me your GeniSys user  \n","3             Great! Hi <HUMAN>! How can I help?  \n","4          Good! Hi <HUMAN>, how can I help you?  "]},"execution_count":179,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.DataFrame(columns=['intent', 'text', 'response'])\n","\n","for d in data:\n","    intent = d['intent']\n","    \n","    for text_, res_ in zip(d['text'], d['responses']):\n","        row = {\"intent\": intent, \"text\": text_, \"response\":res_}\n","        \n","        df= df.append(row, ignore_index=True)\n","        \n","df.head()"]},{"cell_type":"code","execution_count":172,"metadata":{"execution":{"iopub.execute_input":"2023-02-01T12:19:09.987880Z","iopub.status.busy":"2023-02-01T12:19:09.987469Z","iopub.status.idle":"2023-02-01T12:19:09.996709Z","shell.execute_reply":"2023-02-01T12:19:09.995442Z","shell.execute_reply.started":"2023-02-01T12:19:09.987847Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array(['Greeting', 'GreetingResponse', 'CourtesyGreeting',\n","       'CourtesyGreetingResponse', 'CurrentHumanQuery', 'NameQuery',\n","       'RealNameQuery', 'TimeQuery', 'Thanks', 'NotTalking2U',\n","       'UnderstandQuery', 'Shutup', 'Swearing', 'GoodBye',\n","       'CourtesyGoodBye', 'WhoAmI', 'Clever', 'Gossip', 'Jokes',\n","       'PodBayDoor', 'PodBayDoorResponse', 'SelfAware'], dtype=object)"]},"execution_count":172,"metadata":{},"output_type":"execute_result"}],"source":["#total intent in our dataset\n","df.intent.unique()"]},{"cell_type":"markdown","metadata":{},"source":["## **Data Preprocessing**"]},{"cell_type":"code","execution_count":173,"metadata":{"execution":{"iopub.execute_input":"2023-02-01T12:19:11.380091Z","iopub.status.busy":"2023-02-01T12:19:11.379653Z","iopub.status.idle":"2023-02-01T12:19:21.680132Z","shell.execute_reply":"2023-02-01T12:19:21.679208Z","shell.execute_reply.started":"2023-02-01T12:19:11.380043Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["NLTK Downloader\n","---------------------------------------------------------------------------\n","    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n","---------------------------------------------------------------------------\n"]},{"name":"stdout","output_type":"stream","text":["Downloader>  \n"]},{"name":"stdout","output_type":"stream","text":["\n","---------------------------------------------------------------------------\n","    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n","---------------------------------------------------------------------------\n"]},{"name":"stdout","output_type":"stream","text":["Downloader>  \n"]},{"name":"stdout","output_type":"stream","text":["\n","---------------------------------------------------------------------------\n","    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n","---------------------------------------------------------------------------\n"]},{"name":"stdout","output_type":"stream","text":["Downloader>  l\n"]},{"name":"stdout","output_type":"stream","text":["\n","Packages:\n","  [*] abc................. Australian Broadcasting Commission 2006\n","  [*] alpino.............. Alpino Dutch Treebank\n","  [*] averaged_perceptron_tagger Averaged Perceptron Tagger\n","  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n","  [*] basque_grammars..... Grammars for Basque\n","  [ ] bcp47............... BCP-47 Language Tags\n","  [*] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n","                           Extraction Systems in Biology)\n","  [*] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n","  [*] book_grammars....... Grammars from NLTK Book\n","  [*] brown............... Brown Corpus\n","  [*] brown_tei........... Brown Corpus (TEI XML Version)\n","  [*] cess_cat............ CESS-CAT Treebank\n","  [*] cess_esp............ CESS-ESP Treebank\n","  [*] chat80.............. Chat-80 Data Files\n","  [*] city_database....... City Database\n","  [*] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n","  [ ] comparative_sentences Comparative Sentence Dataset\n","  [*] comtrans............ ComTrans Corpus Sample\n","  [*] conll2000........... CONLL 2000 Chunking Corpus\n"]},{"name":"stdout","output_type":"stream","text":["Hit Enter to continue:  l\n"]},{"name":"stdout","output_type":"stream","text":["  [*] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n","  [*] conll2007........... Dependency Treebanks from CoNLL 2007 (Catalan\n","                           and Basque Subset)\n","  [*] crubadan............ Crubadan Corpus\n","  [*] dependency_treebank. Dependency Parsed Treebank\n","  [ ] dolch............... Dolch Word List\n","  [*] europarl_raw........ Sample European Parliament Proceedings Parallel\n","                           Corpus\n","  [ ] extended_omw........ Extended Open Multilingual WordNet\n","  [*] floresta............ Portuguese Treebank\n","  [ ] framenet_v15........ FrameNet 1.5\n","  [ ] framenet_v17........ FrameNet 1.7\n","  [*] gazetteers.......... Gazeteer Lists\n","  [*] genesis............. Genesis Corpus\n","  [*] gutenberg........... Project Gutenberg Selections\n","  [*] ieer................ NIST IE-ER DATA SAMPLE\n","  [*] inaugural........... C-Span Inaugural Address Corpus\n","  [*] indian.............. Indian Language POS-Tagged Corpus\n","  [*] jeita............... JEITA Public Morphologically Tagged Corpus (in\n","                           ChaSen format)\n","  [*] kimmo............... PC-KIMMO Data Files\n"]},{"name":"stdout","output_type":"stream","text":["Hit Enter to continue:  q\n"]},{"name":"stdout","output_type":"stream","text":["\n","---------------------------------------------------------------------------\n","    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n","---------------------------------------------------------------------------\n"]},{"name":"stdout","output_type":"stream","text":["Downloader>  q\n"]}],"source":["import re\n","import nltk\n","nltk.download()\n","\n","from nltk.corpus import stopwords"]},{"cell_type":"code","execution_count":180,"metadata":{"execution":{"iopub.execute_input":"2023-02-01T12:20:07.415222Z","iopub.status.busy":"2023-02-01T12:20:07.414747Z","iopub.status.idle":"2023-02-01T12:20:07.421998Z","shell.execute_reply":"2023-02-01T12:20:07.421099Z","shell.execute_reply.started":"2023-02-01T12:20:07.415182Z"},"trusted":true},"outputs":[],"source":["def text_preprocessing(text):\n","    \"\"\"\n","    converting raw text and response into a string of words. Remove unnecessay data.\n","    Input: Raw string input\n","    output: return clean string\n","    \"\"\"\n","    #removing extra punctuations, numbers and etc\n","    text_only = re.sub(r'[^a-zA-z.?!\\']', \" \", text)\n","    text_only = re.sub(r'[ ]+', ' ', text_only)\n","    \n","    #convert word into lowercase and split\n","    words = text.lower().split()\n","    return(\" \".join(words))\n"]},{"cell_type":"code","execution_count":181,"metadata":{"execution":{"iopub.execute_input":"2023-02-01T12:20:08.220575Z","iopub.status.busy":"2023-02-01T12:20:08.220187Z","iopub.status.idle":"2023-02-01T12:20:08.229118Z","shell.execute_reply":"2023-02-01T12:20:08.227832Z","shell.execute_reply.started":"2023-02-01T12:20:08.220544Z"},"trusted":true},"outputs":[],"source":["text = df['text'].apply(text_preprocessing)\n","resp = df['response'].apply(text_preprocessing)"]},{"cell_type":"code","execution_count":182,"metadata":{"execution":{"iopub.execute_input":"2023-02-01T12:20:08.778588Z","iopub.status.busy":"2023-02-01T12:20:08.777391Z","iopub.status.idle":"2023-02-01T12:20:08.791010Z","shell.execute_reply":"2023-02-01T12:20:08.789783Z","shell.execute_reply.started":"2023-02-01T12:20:08.778545Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>intent</th>\n","      <th>text</th>\n","      <th>response</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Greeting</td>\n","      <td>hi</td>\n","      <td>hi human, please tell me your genisys user</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Greeting</td>\n","      <td>hi there</td>\n","      <td>hello human, please tell me your genisys user</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Greeting</td>\n","      <td>hola</td>\n","      <td>hola human, please tell me your genisys user</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>GreetingResponse</td>\n","      <td>my user is adam</td>\n","      <td>great! hi &lt;human&gt;! how can i help?</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>GreetingResponse</td>\n","      <td>this is adam</td>\n","      <td>good! hi &lt;human&gt;, how can i help you?</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             intent             text  \\\n","0          Greeting               hi   \n","1          Greeting         hi there   \n","2          Greeting             hola   \n","3  GreetingResponse  my user is adam   \n","4  GreetingResponse     this is adam   \n","\n","                                        response  \n","0     hi human, please tell me your genisys user  \n","1  hello human, please tell me your genisys user  \n","2   hola human, please tell me your genisys user  \n","3             great! hi <human>! how can i help?  \n","4          good! hi <human>, how can i help you?  "]},"execution_count":182,"metadata":{},"output_type":"execute_result"}],"source":["df['text'] = text\n","df['response'] = resp\n","df.head()"]},{"cell_type":"code","execution_count":183,"metadata":{"execution":{"iopub.execute_input":"2023-02-01T12:20:14.059273Z","iopub.status.busy":"2023-02-01T12:20:14.058806Z","iopub.status.idle":"2023-02-01T12:20:14.067421Z","shell.execute_reply":"2023-02-01T12:20:14.066000Z","shell.execute_reply.started":"2023-02-01T12:20:14.059236Z"},"trusted":true},"outputs":[],"source":["def check_simialarity(text1, text2):\n","    sentences = [text1, text2]\n","    \n","    #creating a vocabulary with sentences\n","    #Bags of Words\n","    count_vec = CountVectorizer(analyzer = \"word\", max_features=1000)\n","    sentences_vec = count_vec.fit_transform(sentences)\n","    \n","    vocab = count_vec.get_feature_names()\n","    \n","    #converting into an array of list\n","    text1_vec = sentences_vec.toarray()[0].tolist()\n","    text2_vec = sentences_vec.toarray()[1].tolist()\n","    \n","    dist = distance.cosine(text1_vec, text2_vec)\n","    \n","    #calculate the score from distance b/w 0~1\n","    return round((1-dist), 2)"]},{"cell_type":"code","execution_count":184,"metadata":{"execution":{"iopub.execute_input":"2023-02-01T12:20:16.579527Z","iopub.status.busy":"2023-02-01T12:20:16.579094Z","iopub.status.idle":"2023-02-01T12:20:16.587160Z","shell.execute_reply":"2023-02-01T12:20:16.585616Z","shell.execute_reply.started":"2023-02-01T12:20:16.579488Z"},"trusted":true},"outputs":[],"source":["def respond(text):\n","    maximum = float(\"-inf\")\n","    reponse, closet = \"\", \"\"\n","    \n","    for data in df.iterrows():\n","        #get the text score which is similar to input\n","        similarity = check_simialarity(text, data[1]['text'])\n","        \n","        #check the similarity, similarity between 0 to 1\n","        if similarity > maximum:\n","            maximum = similarity\n","            response = data[1]['response']\n","            closest = data[1]['text']\n","        \n","    return response"]},{"cell_type":"code","execution_count":188,"metadata":{"execution":{"iopub.execute_input":"2023-02-01T12:22:05.307659Z","iopub.status.busy":"2023-02-01T12:22:05.306520Z","iopub.status.idle":"2023-02-01T12:23:07.587024Z","shell.execute_reply":"2023-02-01T12:23:07.586193Z","shell.execute_reply.started":"2023-02-01T12:22:05.307610Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Hey! How are you.Let's Chat\n"]},{"name":"stdout","output_type":"stream","text":["\n","Input:  what is your name\n"]},{"name":"stdout","output_type":"stream","text":["Response: you can call me geni\n"]},{"name":"stdout","output_type":"stream","text":["\n","Input:  what are you doing\n"]},{"name":"stdout","output_type":"stream","text":["Response: hi, how are you? i am great thanks! please tell me your genisys user\n"]},{"name":"stdout","output_type":"stream","text":["\n","Input:  give me a tip of self aware\n"]},{"name":"stdout","output_type":"stream","text":["Response: so i went down the local supermarket, i said, 'i want to make a complaint, this vinegar's got lumps in it', he said, 'those are pickled onions'.\n"]},{"name":"stdout","output_type":"stream","text":["\n","Input:  give me a tip of selfaware\n"]},{"name":"stdout","output_type":"stream","text":["Response: so i went down the local supermarket, i said, 'i want to make a complaint, this vinegar's got lumps in it', he said, 'those are pickled onions'.\n"]},{"name":"stdout","output_type":"stream","text":["\n","Input:  q\n"]},{"name":"stdout","output_type":"stream","text":["Response: Bot is going to sleep...\n"]}],"source":["print(\"Hey! How are you.Let's Chat\")\n","while True:\n","    text = str(input(\"\\nInput: \"))\n","    if text.lower() == \"q\":\n","        print(\"Response: Bot is going to sleep...\")\n","        break\n","    print(\"Response:\",respond(text))"]},{"cell_type":"markdown","metadata":{},"source":["## Trying with other way"]},{"cell_type":"code","execution_count":167,"metadata":{"execution":{"iopub.execute_input":"2023-02-01T12:15:56.569877Z","iopub.status.busy":"2023-02-01T12:15:56.569350Z","iopub.status.idle":"2023-02-01T12:16:07.586768Z","shell.execute_reply":"2023-02-01T12:16:07.585606Z","shell.execute_reply.started":"2023-02-01T12:15:56.569828Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]}],"source":["#creating a vocabulary with sentences\n","#Bags of Words\n","count_vec = CountVectorizer(analyzer = \"word\", max_features=1000)\n","sentences_vec = count_vec.fit_transform(df['text'])\n","response_vec = count_vec.fit_transform(df['response'])\n","\n","vocab = count_vec.get_feature_names()\n","#     print(vocab)\n","\n","sentences_vec = sentences_vec.toarray()\n","response_vec = response_vec.toarray()\n","\n","sentences_vec = tf.keras.preprocessing.sequence.pad_sequences(sentences_vec, maxlen=219, padding='pre')\n","response_vec = tf.keras.preprocessing.sequence.pad_sequences(response_vec, maxlen=219, padding='pre')\n","\n","from sklearn.ensemble import RandomForestClassifier\n","\n","# Initialize a Random Forest classifier with 100 trees\n","forest = RandomForestClassifier(n_estimators = 1000) \n","\n","# Fit the forest to the training set, using the bag of words as \n","forest = forest.fit(sentences_vec, response_vec)"]},{"cell_type":"code","execution_count":163,"metadata":{"execution":{"iopub.execute_input":"2023-02-01T12:15:07.238399Z","iopub.status.busy":"2023-02-01T12:15:07.237919Z","iopub.status.idle":"2023-02-01T12:15:16.004296Z","shell.execute_reply":"2023-02-01T12:15:16.003222Z","shell.execute_reply.started":"2023-02-01T12:15:07.238360Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" tell me a joke about anything\n"]}],"source":["text = [input()]"]},{"cell_type":"code","execution_count":168,"metadata":{"execution":{"iopub.execute_input":"2023-02-01T12:16:13.971168Z","iopub.status.busy":"2023-02-01T12:16:13.970710Z","iopub.status.idle":"2023-02-01T12:16:13.978868Z","shell.execute_reply":"2023-02-01T12:16:13.977742Z","shell.execute_reply.started":"2023-02-01T12:16:13.971132Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["  (0, 120)\t1\n","  (0, 182)\t1\n"]}],"source":["import tensorflow as tf\n","# transforming the input and convert to a numpy array\n","test_data_features = count_vec.transform(text)\n","\n","test_data_features = test_data_features.toarray()"]},{"cell_type":"code","execution_count":169,"metadata":{"execution":{"iopub.execute_input":"2023-02-01T12:16:15.939052Z","iopub.status.busy":"2023-02-01T12:16:15.938254Z","iopub.status.idle":"2023-02-01T12:16:17.785301Z","shell.execute_reply":"2023-02-01T12:16:17.783775Z","shell.execute_reply.started":"2023-02-01T12:16:15.939010Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n","      dtype=int32)"]},"execution_count":169,"metadata":{},"output_type":"execute_result"}],"source":["result = forest.predict(test_data_features)\n","result"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.-1"},"vscode":{"interpreter":{"hash":"0df4dddb637ba8aec10a13d922b99bbd287232316513a3a8b2066d6420544039"}}},"nbformat":4,"nbformat_minor":4}
